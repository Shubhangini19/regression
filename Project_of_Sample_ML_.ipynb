{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhangini19/regression/blob/main/Project_of_Sample_ML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Project Name** - Bike Sharing Demand   \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Shubhangini Ganguli"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This TED Talks Views prediction dataset contains 19 features and 4005 observations of 15\n",
        "year, i.e., from 1-12-2017 to 31-11-2018. We have a regression problem because our target is\n",
        "the number of rented bikes per hour. This Regression analysis helps to achieve the goal of the\n",
        "company Seoul Bike in providing the city with a stable supply of rental bikes. It becomes a\n",
        "major concern to keep users satisfied. The crucial part is the prediction of bike count required at\n",
        "each hour for the stable supply of rental bikes.\n",
        "After loading the dataset, firstly, we performed data preprocessing, we did some data\n",
        "exploration by checking types, missing values, duplicate values and data description. In this\n",
        "dataset there are neither null values nor duplicate values. We also changed the date type to\n",
        "Date Time which was initially a str object. From the date, we also created three columns with\n",
        "the day of the week and the month and the year corresponding. We also changed the datatype\n",
        "of the hour feature from int to object.\n",
        "After that, we performed Exploratory Data Analysis to obtain the insights of our dependent\n",
        "variable Rented Bike Counts. Various graphs were constructed comparing the Rented Bike\n",
        "Count column with other columns. List of insights were obtained. We observed that bike rental\n",
        "count is higher during weekdays than weekend days. The rental bike counts are at its peak at 8\n",
        "AM in the morning and 6pm in the evening. Highest rental bike count is during Autumn and\n",
        "summer seasons and the lowest in winter season.\n",
        "Next step was feature engineering, in which we detected and took care of multicollinearity.\n",
        "We used the square root method to normalize the target variable. For scaling independent\n",
        "features, we used Yeo Johnson transformation technique. Lastly, we used Pandas dummies\n",
        "for encoding the categorical features.\n",
        "Now the modeling part begins, here we used 8 regression algorithms, viz., Linear Regression,\n",
        "Ridge, Lasso, Polynomial, Decision Tree, Random Forest Regressor, Gradient Boosting\n",
        "Regressor and Extra Trees Regressor. So, after fitting the models and evaluating metrics (MSE,\n",
        "RMSE, R Square, Adjusted R Square) and also hyperparameter tuning we came to the\n",
        "result and conclusion. We got the Adjusted R2 among all the models, Extra Trees Regressor\n",
        "gives the highest Score where Adjusted R2 score is 0.908699 and Training score is 0.987167.\n",
        "Therefore, this model is the best for predicting the bike rental count on an hourly basis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Shubhangini19/regression"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually,providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.    "
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount the google drive in google colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s8x0Gu0Dg8bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (10,6)\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "path = '/content/SeoulBikeData.csv'\n",
        "df = pd.read_csv(path,encoding = 'latin' ,parse_dates=['Date'])"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First five rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Last five rows\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "c0GJEHf4kpU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   This data set consist of 8760 rows and 14 columns.\n",
        "*   If we observe the data column,in the dataset,it begins from 1-12-2017 to 30-11-2018.That means we have exact 1 year of seoul bike sharing demand data.\n",
        "\n",
        "*   Value count of missing value is also 0.\n",
        "*   From 14 features our target feature is Rented Bike Count and rest are independent features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above you can see the count of dataset is 8760. In this maximum value is 3356 of Rented Bike count.Mean of wind speed is 1.724909.Std of snowfall is 0.436746.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create the seperate date,month,year by extracting from the date column and then drop the date column."
      ],
      "metadata": {
        "id": "qWrk95xWOTx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract day from date\n",
        "df['WeekDay']=df[\"Date\"].dt.day_name()\n",
        "#extract month from date\n",
        "df['Month']=pd. DatetimeIndex(df['Date']).month_name()\n",
        "#extract year from date\n",
        "df['year']=df['Date'].dt.strftime('%Y')"
      ],
      "metadata": {
        "id": "rC078Zf9DdIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8tczXGCoEhuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the date column as we extracted all formats of date and keep them in seperate columns respectively.\n",
        "df.drop(columns=['Date'],inplace=True)"
      ],
      "metadata": {
        "id": "yibxxDEWErXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking outliers\n",
        "C = ['Rented Bike Count','Temperature(°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','Solar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']\n",
        "n = 1\n",
        "plt.figure(figsize=(18,12))\n",
        "\n",
        "for i in C:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df[i])\n",
        "  plt.title(i)\n",
        "  plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "NT6gdQGK1HAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Hour column integer to Categorical\n",
        "df['Hour']=df['Hour'].astype('object')"
      ],
      "metadata": {
        "id": "TOPVlPk3FZiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the outlier in rainfall and snowfall columns but we don't have to worry about outliers in this data, because if we treat the outliers from Rainfall and snowfall columns, it removes all the information of the data.\n",
        "Now we will create the seperate date,month,year by extracting from the date column and then will drop the date column.Hour column datatype is of integer.But the date column is of timestamp and 'hour' the part of timestamp.So it should be the categorical column."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the default fig size \n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (10,6)"
      ],
      "metadata": {
        "id": "DjiP3OboH-V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 Box PLot\n",
        "C_columns=['Seasons','Hour','Holiday','WeekDay','year','Month']\n",
        "n=1\n",
        "plt.figure(figsize=(20,12))\n",
        "for i in C_columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(x=df[i],y=df['Rented Bike Count'])\n",
        "  plt.title(f\"Count over {i}\")\n",
        "  plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives clear picture and helps to analyse ."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   In count over Seasons, the demand for bike in Winter is less than compare to summer and other seasons.\n",
        "\n",
        "*   In count over Hour, if we observe during the day,the demand for bikes is high from morning 8am and from evening 6pm.\n",
        "*   Demand for the rented bike during No Holiday is higher than the holiday.\n",
        "\n",
        "*   Now in Count over Month graph, if we observe carefully,the demand for the bike is lesser in the months which are December,January,Februraryas at that time it is the winter season.\n",
        "*   In the months such as April,May,June the demand for the bike is higher because these months  fall in Summer Seasons.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Distribution of target column\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(df['Rented Bike Count'],bins=50,color='orange',)\n",
        "plt.axvline(df['Rented Bike Count'].mean(), color='red', linestyle='dashed', linewidth=3)\n",
        "plt.axvline(df['Rented Bike Count'].median(), color='indigo', linestyle='dotted', linewidth=3)\n",
        "plt.show()\n",
        "sns.distplot(df['Rented Bike Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 normalizing the distribution of target column using sqaure root\n",
        "sns.displot(np.sqrt(df['Rented Bike Count']),color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its Provides insights which is visibly clear.\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   The shape of the Rented Bike Count feature is RIGHTLY SKEWED.\n",
        "\n",
        "1.  We have transform this distribution info approx normal distribution using appropriate transformation tecniques.\n",
        "2.   We used square root transformation,as it transforming this skewed distribution into normal. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 seeing the data distribution of the numerical features\n",
        "N = df[['Temperature(°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','Solar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']]\n",
        "n=1\n",
        "for i in N:\n",
        "  plt.subplot(9,3,n)\n",
        "  plt.figure(figsize=(10,8))\n",
        "  n+=1\n",
        "  sns.distplot(df[i],color = 'indigo')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "g1zzl9_NUC-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see,bike count is more in the year 2018 than 2017. "
      ],
      "metadata": {
        "id": "PvKijnKRUPUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 total number of rented bike count per season\n",
        "dfSeasons=pd.DataFrame(df.groupby('Seasons').sum()['Rented Bike Count'].sort_values(ascending=False))\n",
        "dfSeasons"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSeasons.plot(kind='bar',color=['red','blue','pink','black'],y='Rented Bike Count')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "VUkDUAhC7X9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  What is/are the insight(s) found from the chart?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bike count in the summer season is more.While in winter the count is less."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 Rented Bike Count during Days of the Week\n",
        "fig,ax=plt.subplots(figsize=(21,9))\n",
        "sns.pointplot(x='Hour',y='Rented Bike Count',hue='WeekDay',data = df,ax=ax)\n",
        "ax.set(title='Rented Bike Count per hour during Days of the Week')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide everything in detail."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Here, From Monday to Friday we consider as a Weekdays while Saturday,Sunday considered as Weekends. \n",
        "\n",
        "*  If we closely look into this pointplot,eiher its weekdays or weekends,the demand for rented bike count approx starts from morning 6am.At 8am its high and also from 6pm. \n",
        "* The bike count is high in weekdays than  weekend.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 Rented bike count per day with respect to Month\n",
        "fig,ax=plt.subplots(figsize=(21,9))\n",
        "sns.pointplot(x='Hour',y='Rented Bike Count',hue='Month',data = df,ax=ax)\n",
        "ax.set(title='Rented Bike Count with respect to Month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   By observing, we get to know that in the month of December,January,February the demand for bike is less due to cold weather.\n",
        "*  Although the pattern is same with respect to hour,as demand gets peak at 8am and 6am. \n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 rented bike count per hour wiht respect to Seasons\n",
        "fig,ax=plt.subplots(figsize=(21,9))\n",
        "sns.pointplot(x='Hour',y='Rented Bike Count',hue='Seasons',data = df,ax=ax)\n",
        "ax.set(title='Rented Bike Count vs Seasons')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We already seen before in boxplots,that the demand for bike in summer is high and in winters is low. \n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 sum percentage distribution of the rented bike count with respect to seasons\n",
        "df.groupby('Seasons').sum()['Rented Bike Count'].plot.pie(autopct=\"%.2f%%\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 average bike count with respect to weekdays\n",
        "df.groupby('WeekDay')['Rented Bike Count'].mean().plot.barh(color=['yellow','indigo','blue','green','gold','orange','red'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 seeing the climate(sunlight) during the day\n",
        "df.groupby('Hour').sum()['Solar Radiation (MJ/m2)'].plot(kind='bar',color='red',)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that the sunlight comes at 8am and it rises it peakes in the afternoon around 1pm an gradually decreases till 6pm.That's why people mostly used rented bike during these hours."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 percentage distribution of the value counts of the categorical features\n",
        "col=['Month','Holiday','Seasons','year','WeekDay','Functioning Day']\n",
        "n=1\n",
        "plt.figure(figsize=(20,15))\n",
        "for i in col:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  plt.pie(df[i].value_counts(),labels = df[i].value_counts().keys().tolist(),autopct='%.f%%')\n",
        "  plt.title(i)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Month feature is equally distributed.\n",
        "\n",
        "*   In holiday features,No holiday is 95% distributed and 5% of holiday.\n",
        "*   In season column, all season labels is 25% distributed equally.\n",
        "\n",
        "\n",
        "*   In year column,2017=8% 2018=92%\n",
        "\n",
        "*   Functioning day,yes=97% no = 3%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13-Pair Plot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - percentage distribution of the value counts of the categorical features\n",
        "sns.pairplot(df,corner=True,)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - "
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Plots to know the relation between target variable\n",
        "fig,(ax1,ax2,ax3)= plt.subplots(ncols=3, figsize = (22,5))\n",
        "sns.regplot(df['Temperature(°C)'], df['Rented Bike Count'],scatter_kws={\"color\": \"orange\"}, line_kws={\"color\": \"red\"},ax=ax1)\n",
        "ax1.set(title='Relation b/w Target variable and Tenperature')\n",
        "sns.regplot(df['Humidity(%)'], df['Rented Bike Count'],scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"},ax=ax2)\n",
        "ax1.set(title='Relation b/w Target variable and Humidity')\n",
        "sns.regplot(df['Solar Radiation (MJ/m2)'], df['Rented Bike Count'],scatter_kws={\"color\": \"green\"}, line_kws={\"color\": \"red\"},ax=ax3)\n",
        "ax1.set(title='Relation b/w Target variable and Solar Radiation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Correlation Heatmap "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix\n",
        "plt.figure(figsize=(13,10))\n",
        "plt.title(\"Correlation Between Different Variables\\n\")\n",
        "sns.heatmap(abs(df.corr()),\n",
        "            cmap='hot', annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  From this correlation matrix,we can easily say that Temperature and Dew point has higher correlation between them i.e.0.91 which is good but it will badly affect while training the model and doing prediction.\n",
        "*   This type of high correlation is also called as multicollinearity.\n",
        "*  I used VIF technique to detect multicollinearity seperately and then i decided to remove one of the column which is Dew point temperature.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hlAsJf3PXodN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation between target variable and remaining independent variable\n",
        "df.corr()['Rented Bike Count']"
      ],
      "metadata": {
        "id": "twrsFovbgEvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some features are negatively correlated and some positive with the target feature."
      ],
      "metadata": {
        "id": "F1uEHH4_giHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#detecting multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "A =  df[['Temperature(°C)','Dew point temperature(°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','Solar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']]\n",
        "VIF = pd.DataFrame()\n",
        "VIF[\"feature\"] = A.columns\n",
        "#calculating VIF\n",
        "VIF[\"Variance Inflation Factor\"] = [ variance_inflation_factor(A.values,i)\n",
        "                          for i in range(len(A.columns))]\n",
        "print(VIF)"
      ],
      "metadata": {
        "id": "fTfgsDEwgX7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that Temperature and Dew point temperature has high VIF.\n",
        "\n",
        "Let's see the VIF after removing dew pont temperature features from the list."
      ],
      "metadata": {
        "id": "GdAYxH70iyk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VIF after removing the dew point temperature feature\n",
        "A = df[['Temperature(°C)','Humidity(%)','Wind speed (m/s)','Visibility (10m)','Solar Radiation (MJ/m2)','Rainfall(mm)','Snowfall (cm)']]\n",
        "VIF = pd.DataFrame()\n",
        "VIF[\"Feature\"] = A.columns\n",
        "#calculating VIF\n",
        "VIF[\"Variance Inflation Factor\"] = [ variance_inflation_factor(A.values,i)\n",
        "                          for i in range(len(A.columns))]\n",
        "print(VIF)"
      ],
      "metadata": {
        "id": "LffJRFitjFaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the VIF score is normal which is between 1-5. Therefore i decided that it is better to remove the dew point temperature feature from the dataset."
      ],
      "metadata": {
        "id": "FEp3IMcRIFha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the dew point temperature feature\n",
        "df=df.drop(['Dew point temperature(°C)'],axis=1)"
      ],
      "metadata": {
        "id": "eD2_Zj1vj3_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding process"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical features\n",
        "final_df=pd.get_dummies(df,drop_first=True,sparse=True)\n",
        "final_df.head(3).T\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Dividing the data"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the data into dependent variable(target) and independent variable\n",
        "x = final_df.drop('Rented Bike Count',axis=1)\n",
        "y = np.sqrt(final_df['Rented Bike Count'])"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. train_test_split"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required library\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split the data.\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.25,random_state=42)"
      ],
      "metadata": {
        "id": "Iv5sUPfa87vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "metadata": {
        "id": "ujtjXNRq9jq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head()"
      ],
      "metadata": {
        "id": "mVeGfRT59o6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "vXCmlJC-9wZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Model Training***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the models from sklearn library\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,HistGradientBoostingRegressor,ExtraTreesRegressor\n",
        "\n",
        "#import evaluating metrices\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "from math import sqrt\n",
        "\n",
        "#import GridSearchCV for hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining functions for finding metrics"
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appending all models evaluation scores to the corresponding list after hyperparameter\n",
        "MSE_ht=[]\n",
        "RMSE_ht=[]\n",
        "training_score_ht =[]\n",
        "R2_ht=[]\n",
        "ADJ_R2_ht=[]"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a function for training the model and also the calculating the evaluation metrics\n",
        "def eval_metric(model_name,X_train,X_test,y_train,y_test,linear = False):\n",
        "  '''\n",
        "\n",
        "    Defining the function to find the all evaluating metric scores\n",
        "\n",
        "  '''  \n",
        "  model_name.fit(X_train,y_train) #...fitting the model\n",
        "  tr = model_name.score(X_train,y_train)#....to see the training set score\n",
        "  print(\"Training_score =\", tr)\n",
        "  try:\n",
        "    print(\"The best parameters is\",model_name.best_params_)\n",
        "  except:\n",
        "    print('None')\n",
        "  if linear == True:\n",
        "    Y_pred = model_name.predict(X_test)\n",
        "    mse = mean_squared_error(y_test**2,Y_pred**2) #......... mean_squared_error\n",
        "    print(\"MSE :\" , mse)\n",
        "    rmse = np.sqrt(mse) #..........root mean squared error\n",
        "    print(\"RMSE :\" ,rmse)\n",
        "   \n",
        "    r2 = r2_score(y_test**2,Y_pred**2) #.......... r2 score\n",
        "    print(\"R2 :\" ,r2)\n",
        "    \n",
        "    adj_r2=1-(1-r2_score(y_test**2,Y_pred**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) # ........adjusted r2 score\n",
        "    print(\"Adjusted_R2 : \",adj_r2,'\\n')\n",
        "  else:\n",
        "\n",
        "    Y_pred = model_name.predict(X_test)#.......for tree based models\n",
        "\n",
        "    mse = mean_squared_error(y_test,Y_pred)\n",
        "    print(\"MSE :\" , mse)\n",
        "\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(\"RMSE :\" ,rmse)\n",
        "    \n",
        "    r2 = r2_score(y_test,Y_pred)\n",
        "    print(\"R2 :\" ,r2)\n",
        "   \n",
        "    adj_r2=1-(1-r2_score(y_test,Y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "    print(\"Adjusted R2 : \",adj_r2,'\\n')\n",
        "\n",
        "  #appending all metrics for all models\n",
        "  MSE_ht.append(mse)\n",
        "  RMSE_ht.append(rmse)  \n",
        "  R2_ht.append(r2)\n",
        "  ADJ_R2_ht.append(adj_r2)\n",
        "  training_score_ht.append(tr)\n",
        "\n",
        "  if model_name == Lr:\n",
        "    print('Coefficient:',model_name.coef_) # ..... Coeff of linear model\n",
        "    print('\\n')\n",
        "    print('Intercept:',model_name.intercept_) # ......intercept of linear model\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "pWTeY2GKD2hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "while doing power trasform,we should take care of some ponts:-\n",
        "\n",
        "\n",
        "1.   No null values\n",
        "2.   No negative value\n",
        "\n",
        "1.   No O\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fdHP1YutG7Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature transformation using Yeo Johnson transformation technique\n",
        "from sklearn.preprocessing import PowerTransformer,MinMaxScaler\n",
        "powertrans_ = PowerTransformer()\n",
        "x_train_trans = powertrans_.fit_transform(x_train) #........ fit transform the training set\n",
        "X_test_trans = powertrans_.transform(x_test)\n"
      ],
      "metadata": {
        "id": "-_2QY9GYH5q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### All Models without hyperparameter tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE=[]\n",
        "RMSE=[]\n",
        "training_score =[]\n",
        "R2=[]\n",
        "ADJ_R2=[]\n",
        "\n",
        "# assigning models in variables\n",
        "lr= LinearRegression()\n",
        "l2 = Ridge()\n",
        "l1 = Lasso()\n",
        "\n",
        "linear_models = [lr,l1,l2]\n",
        "for model_name in linear_models:\n",
        "  model_name.fit(x_train_trans,y_train)\n",
        "  y_pred = model_name.predict(X_test_trans)\n",
        "  mse1 = mean_squared_error(y_test,y_pred)\n",
        "  rmse1 = np.sqrt(mse1)\n",
        "  r21 = r2_score(y_test,y_pred)\n",
        "  ad_r21 =1-(1-r21)*((X_test_trans.shape[0]-1)/(X_test_trans.shape[0]-X_test_trans.shape[1]-1))\n",
        "\n",
        "  training_score.append(model_name.score(x_train_trans,y_train))\n",
        "  MSE.append(mse1)\n",
        "  RMSE.append(rmse1)\n",
        "  R2.append(r21)\n",
        "  ADJ_R2.append(ad_r21)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_score"
      ],
      "metadata": {
        "id": "18FimphSJhI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear models with Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Regression"
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lr =LinearRegression()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the linear regression model into define function\n",
        "eval_metric(Lr,x_train,x_test,y_train,y_test,linear = True)"
      ],
      "metadata": {
        "id": "zm8CwQ2_LZPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regularization = Lasso"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using grid search CV for hyperparameter tuning of LASSO\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]} #lasso parameters \n",
        "L_lasso = GridSearchCV(Lasso(), parameters, cv=5) #using gridsearchcv and cross validate the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting and calculation metric by calling the define function\n",
        "eval_metric(L_lasso,x_train,x_test,y_train,y_test,linear = True)"
      ],
      "metadata": {
        "id": "Pl4smPiY4TUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization = Ridge"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using grid search CV for hyperparameter tuning of LASSO\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]} #lasso parameters \n",
        "L_lasso = GridSearchCV(Lasso(), parameters, cv=5) #using gridsearchcv and cross validate the model"
      ],
      "metadata": {
        "id": "Btue3Wwz5Y_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(L_lasso,x_train,x_test,y_train,y_test,linear = True)"
      ],
      "metadata": {
        "id": "sf48Yyha5nRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial"
      ],
      "metadata": {
        "id": "7AA8hM0F6kwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### With polynomial degree 2"
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "polynomial_2 = PolynomialFeatures(2) #........creating variable with degree 2\n",
        "poly_x_train2 = polynomial_2.fit_transform(x_train_trans) #........ fitting the train set\n",
        "poly_X_test2 = polynomial_2.transform(X_test_trans) #.........transforming the test set\n"
      ],
      "metadata": {
        "id": "Bg50HFvj6zcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(Lr,poly_x_train2,poly_X_test2,y_train,y_test,linear = True)"
      ],
      "metadata": {
        "id": "EnQDEk-g603q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now,Tree Based Models without Hyperparametere"
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "scaling = MinMaxScaler()"
      ],
      "metadata": {
        "id": "BBquQrQa8q5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = scaling.fit_transform(x_train) #......fitting the X_train\n",
        "X_test_scaled = scaling.transform(x_test) # transform test set"
      ],
      "metadata": {
        "id": "qMiuXPI69L10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning the models into new variables\n",
        "d_tree= DecisionTreeRegressor()\n",
        "r_forest = RandomForestRegressor()\n",
        "g_boost = GradientBoostingRegressor()\n",
        "xt_boost = ExtraTreesRegressor()\n",
        "\n",
        "tree_models = [d_tree,r_forest,g_boost,xt_boost]\n",
        "for model_name in tree_models:\n",
        "  model_name.fit(X_train_scaled,y_train)\n",
        "  y_pred = model_name.predict(X_test_scaled)\n",
        "  mse = mean_squared_error(y_test,y_pred)\n",
        "  rmse = np.sqrt(mse)\n",
        "  r2 = r2_score(y_test,y_pred)\n",
        "  ad_r2 =1-(1-r2)*((X_test_scaled.shape[0]-1)/(X_test_scaled.shape[0]-X_test_scaled.shape[1]-1))\n",
        "#appending the metrics into pre defined metric variables\n",
        "  training_score.append(model_name.score(X_train_scaled,y_train))\n",
        "  MSE.append(mse)\n",
        "  RMSE.append(rmse)\n",
        "  R2.append(r2)\n",
        "  ADJ_R2.append(ad_r2)\n"
      ],
      "metadata": {
        "id": "QGzUysGp9TcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Dataframe of all metrics without hyperparameter tuning"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all models into a list and storing in a new variable\n",
        "models = ['Linear Regression','Ridge','Lasso','Decision_Tree','Random_Forest','Gradient_boost','ExtraTreeReg']\n",
        "\n",
        "# Creating dictionary of evaluating metrics by creating new names\n",
        "metrics = {'TRAININGSCORE':training_score,'MSE':MSE,'RMSE':RMSE,'R2':R2,'ADJ_R2':ADJ_R2}\n",
        "\n",
        "# creating the dataframe of all metrics without hyperparameter tuning\n",
        "metrics_df = pd.DataFrame.from_dict(metrics,orient='index',columns=models)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df.T"
      ],
      "metadata": {
        "id": "fnVAKf-b9ulc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RandomForest,GradientBoost and ExtraTreRegession giving nest ADJ_R2 score.But there are overfitting in them.So,Hyperparameter tuning is must."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tree Models with Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Fpx90tmaRbH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "ByC2eGhj-WZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for Decission Tree model\n",
        "parameters = {'criterion':['mse'],#'squared_error', 'absolute_error',],\n",
        "              'min_samples_leaf':[5],#7,10],\n",
        "              'max_depth' : [18],#10,25],\n",
        "              'min_samples_split': [25],#15,35],\n",
        "              'max_features':['auto'],#'sqrt','log2']\n",
        "              }"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We put other parameters under comments as we found the best parameters among them."
      ],
      "metadata": {
        "id": "Gc-FH4uy-mOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using grid search CV\n",
        "D_tree = GridSearchCV(DecisionTreeRegressor(),param_grid=parameters,cv=5,n_jobs=-1)"
      ],
      "metadata": {
        "id": "f9T2Yusb--vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(D_tree,X_train_scaled,X_test_scaled,y_train,y_test)"
      ],
      "metadata": {
        "id": "dkig-TYC-_QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RandomForestRegressor"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameterss = {'n_estimators':[150],#100,200],\n",
        "              'min_samples_leaf':[4],#6,2],\n",
        "              'max_depth' : [20],#25,30],\n",
        "              'min_samples_split': [25],#30,20],\n",
        "              'max_features':['auto'],#'sqrt','log2']\n",
        "              }\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using grid search cv for hyperparameter\n",
        "Random_forest_= GridSearchCV(RandomForestRegressor(),param_grid=parameterss,n_jobs=-1,cv=5)"
      ],
      "metadata": {
        "id": "PqPbIdW3AADq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(Random_forest_,X_train_scaled,X_test_scaled,y_train,y_test)"
      ],
      "metadata": {
        "id": "IZ-mfyogAAb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parametersss={'loss':['huber'],#'squared_error', 'absolute_error','quantile'],\n",
        "            'min_impurity_decrease':[0.4],#0.2,0.6],\n",
        "            'criterion':['mse'],#'mae'],\n",
        "            'n_estimators':[800],#600,400,1000], \n",
        "            'learning_rate': [0.01],#0.03,0.1,0.05], \n",
        "            'min_samples_leaf':[6],#4,8]\n",
        "            'max_depth':[25],#15,20,30],\n",
        "            'subsample':[0.7],#0.5,1.0],\n",
        "            'max_leaf_nodes':[17],#15,10,20],\n",
        "            'max_features':['auto']#'sqrt', 'log2'] \n",
        "            }"
      ],
      "metadata": {
        "id": "Dvxn_-MLAtuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_boost_ = GridSearchCV(GradientBoostingRegressor(), param_grid=parametersss, n_jobs=-1,cv=5,verbose=2)"
      ],
      "metadata": {
        "id": "XD-dH5cxBMcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(gradient_boost_,X_train_scaled,X_test_scaled,y_train,y_test)"
      ],
      "metadata": {
        "id": "9GUW3WLMBNQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ExtraTreesRegressor"
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'n_estimators' : [100], \n",
        "         'max_depth' : [50],#60,70,80,90,100],\n",
        "         'min_samples_split':[2],\n",
        "         'min_samples_leaf':[1],\n",
        "         'bootstrap' : [True],#False]\n",
        "        }\n",
        "\n",
        "# using grid search cv for hyperparameter\n",
        "ExtraTrees_=GridSearchCV(ExtraTreesRegressor(),param_grid=param,n_jobs=-1,cv=5)\n",
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(ExtraTrees_,X_train_scaled,X_test_scaled,y_train,y_test)\n"
      ],
      "metadata": {
        "id": "tz6V4ZI0B7Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all models into a list and storing in a new variable\n",
        "models_ht = ['Linear Regression','Ridge','Lasso','Polynomial','Decision_Tree','Random_Forest','Gradient_boost','ExtraTreesReg']\n",
        "# Creating dictionary of evaluating metrics by creating new names\n",
        "metrics_ht = {'TRAININGSCORE(ht)':training_score_ht,'MSE(ht)':MSE_ht,'RMSE(ht)':RMSE_ht,'R2(ht)':R2_ht,'ADJ_R2(ht)':ADJ_R2_ht}\n",
        "# creating the dataframe of all metrics with hyperparameter tuning\n",
        "metrics_df_ht = pd.DataFrame.from_dict(metrics_ht,orient='index',columns=models_ht)"
      ],
      "metadata": {
        "id": "u_t1ieOnDA7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting dataframe by adj_r2(ht)\n",
        "T_ht = metrics_df_ht.T.sort_values('ADJ_R2(ht)',ascending=False)"
      ],
      "metadata": {
        "id": "BVgiU1-VDOeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_ht"
      ],
      "metadata": {
        "id": "_jVXFJ7_DPS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: 1) After hyperparameter tuning, we can consider the top three model but among them the best model is the Extra Trees regressor with a R2 score of 0.91573 and ADJ_R2 score of 0.909379"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# again training the ExtraTreesRegressor model to check the error between test data and predicted data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y, test_size=0.25,random_state=42)"
      ],
      "metadata": {
        "id": "WufOPnb_EJGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# again training the ExtraTreesRegressor model to check the error between test data and predicted data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y, test_size=0.25,random_state=42)"
      ],
      "metadata": {
        "id": "TePMU1MWEDYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# again training the ExtraTreesRegressor model to check the error between test data and predicted data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y, test_size=0.25,random_state=42)"
      ],
      "metadata": {
        "id": "2H7BXMsUECkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: we saw all model's error b/w test and predicted data. So, among all of them, extratreesregressor gives less error compare to others."
      ],
      "metadata": {
        "id": "jF6nUOCbEwD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting and calculating metric by calling the defined function\n",
        "eval_metric(gradient_boost_,X_train_scaled,X_test_scaled,y_train,y_test)"
      ],
      "metadata": {
        "id": "BFoSsBu8FFvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1) We observed that bike rental count is high during week days then weekend days.\n",
        "\n",
        "2) The rental bike counts are at its peak at 8 AM in the morning and 6pm in the evening.\n",
        "\n",
        "3) We observed that people prefer to rent bikes during moderate to high temperature.\n",
        "\n",
        "4) Highest rental bike count is during Autumn and summer seasons and the lowest in winter season.\n",
        "\n",
        "5) Comparing the Adjusted R2 among all the models, ExtarTreesRegressor gives the highest Score where Adjusted R2 score is 0.908699 and Training score is 0.987167. Therefore, this model is the best for predicting the bike rental count on hour basis."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}